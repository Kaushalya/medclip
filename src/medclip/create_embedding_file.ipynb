{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import os\n",
    "import jax\n",
    "\n",
    "from transformers import AutoTokenizer, CLIPProcessor\n",
    "from configuration_hybrid_clip import HybridCLIPConfig\n",
    "from modeling_hybrid_clip import FlaxHybridCLIP\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from torchvision.transforms import Resize, Normalize, ConvertImageDtype, ToTensor\n",
    "import numpy as np\n",
    "from run_hybrid_clip import Transform"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "model = FlaxHybridCLIP.from_pretrained(\"flax-community/medclip-roco\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "vision_model_name = \"openai/clip-vit-base-patch32\"\n",
    "img_dir = \"/Users/kaumad/Documents/coding/hf-flax/demo/medclip-roco/images\"\n",
    "\n",
    "processor = CLIPProcessor.from_pretrained(vision_model_name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of ftfy.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import pandas as pd\n",
    "\n",
    "img_list = os.listdir(img_dir)\n",
    "embeddings = []\n",
    "\n",
    "for idx, img_path in enumerate(img_list):\n",
    "    if idx % 50 == 0:\n",
    "        print(f\"{idx} images processed\")\n",
    "    img = Image.open(os.path.join(img_dir, img_path)).convert('RGB')\n",
    "    inputs = processor(images=img, return_tensors=\"jax\", padding=True)\n",
    "    inputs['pixel_values'] = inputs['pixel_values'].transpose(0, 2, 3, 1)\n",
    "    img_vec = model.get_image_features(**inputs)\n",
    "    img_vec = np.array(img_vec).reshape(-1).tolist()\n",
    "    embeddings.append(img_vec)\n",
    "    # fvec.write(f\"{img_path}\\t{img_vec_s}\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 images processed\n",
      "50 images processed\n",
      "100 images processed\n",
      "150 images processed\n",
      "200 images processed\n",
      "250 images processed\n",
      "300 images processed\n",
      "350 images processed\n",
      "400 images processed\n",
      "450 images processed\n",
      "500 images processed\n",
      "550 images processed\n",
      "600 images processed\n",
      "650 images processed\n",
      "700 images processed\n",
      "750 images processed\n",
      "800 images processed\n",
      "850 images processed\n",
      "900 images processed\n",
      "950 images processed\n",
      "1000 images processed\n",
      "1050 images processed\n",
      "1100 images processed\n",
      "1150 images processed\n",
      "1200 images processed\n",
      "1250 images processed\n",
      "1300 images processed\n",
      "1350 images processed\n",
      "1400 images processed\n",
      "1450 images processed\n",
      "1500 images processed\n",
      "1550 images processed\n",
      "1600 images processed\n",
      "1650 images processed\n",
      "1700 images processed\n",
      "1750 images processed\n",
      "1800 images processed\n",
      "1850 images processed\n",
      "1900 images processed\n",
      "1950 images processed\n",
      "2000 images processed\n",
      "2050 images processed\n",
      "2100 images processed\n",
      "2150 images processed\n",
      "2200 images processed\n",
      "2250 images processed\n",
      "2300 images processed\n",
      "2350 images processed\n",
      "2400 images processed\n",
      "2450 images processed\n",
      "2500 images processed\n",
      "2550 images processed\n",
      "2600 images processed\n",
      "2650 images processed\n",
      "2700 images processed\n",
      "2750 images processed\n",
      "2800 images processed\n",
      "2850 images processed\n",
      "2900 images processed\n",
      "2950 images processed\n",
      "3000 images processed\n",
      "3050 images processed\n",
      "3100 images processed\n",
      "3150 images processed\n",
      "3200 images processed\n",
      "3250 images processed\n",
      "3300 images processed\n",
      "3350 images processed\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "OSError",
     "evalue": "image file is truncated (8 bytes not processed)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lj/gwd01lcd0h7bbvzq_1w6tdkm0000gn/T/ipykernel_94996/2135400779.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{idx} images processed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"jax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pixel_values'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pixel_values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/coding/miniconda3/envs/flax_p38/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \"\"\"\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/coding/miniconda3/envs/flax_p38/lib/python3.8/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                                     raise OSError(\n\u001b[0m\u001b[1;32m    250\u001b[0m                                         \u001b[0;34m\"image file is truncated \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                                         \u001b[0;34mf\"({len(b)} bytes not processed)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: image file is truncated (8 bytes not processed)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "np.array(embeddings).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3385, 512)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "query = 'carcinoma'\n",
    "inputs = processor(text=[query], images=None, return_tensors=\"jax\", padding=True)\n",
    "\n",
    "query_vec = model.get_text_features(**inputs)\n",
    "query_vec = np.asarray(query_vec)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "query_vec = query_vec / np.linalg.norm(query_vec, axis=-1, keepdims=True)\n",
    "embeddings = embeddings / np.linalg.norm(embeddings, axis=-1, keepdims=True)\n",
    "products = np.sum(np.multiply(query_vec, embeddings), axis=1)\n",
    "products.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "embeddings = np.array(embeddings)\n",
    "embeddings = embeddings / np.linalg.norm(embeddings, axis=-1, keepdims=True)\n",
    "embeddings = [np.asarray(embed) for embed in embeddings.tolist()]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "len(embeddings)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3385"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "embeddings_df = pd.DataFrame({'files': img_list[:3385], 'image_embedding': embeddings})\n",
    "pd.to_pickle(embeddings_df, \"../../data/image_embeddings_large.pkl\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "embeddings_df = pd.read_pickle(\"../../data/image_embeddings.pkl\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "image_embeds = np.asarray(embeddings_df['image_embedding'])\n",
    "image_list = np.asarray(embeddings_df['files'].tolist())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "np.stack(embeddings_df['image_embedding']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(200, 512)"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "image_list[products.argsort()[-5:]]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['PMC2693557_jkms-22-159-g001.jpg',\n",
       "       'PMC2553898_AU2008-918050.003.jpg',\n",
       "       'PMC2684097_1749-7922-4-18-2.jpg', 'PMC2697535_tcrm-5-301f1.jpg',\n",
       "       'PMC2438313_1757-1626-1-10-1.jpg'], dtype='<U40')"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}